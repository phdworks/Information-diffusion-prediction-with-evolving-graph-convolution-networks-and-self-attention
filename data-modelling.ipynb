{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:04:25.034927Z",
     "iopub.status.busy": "2021-01-31T22:04:25.029822Z",
     "iopub.status.idle": "2021-01-31T22:05:35.243447Z",
     "shell.execute_reply": "2021-01-31T22:05:35.242214Z"
    },
    "papermill": {
     "duration": 70.248547,
     "end_time": "2021-01-31T22:05:35.243702",
     "exception": false,
     "start_time": "2021-01-31T22:04:24.995155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\r\n",
      "10.2\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "!python -c \"import torch; print(torch.version.cuda)\"\n",
    "!pip -q install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
    "!pip -q install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
    "!pip -q install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
    "!pip -q install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html\n",
    "!pip -q install torch-geometric\n",
    "!pip -q install torch-geometric-temporal\n",
    "\n",
    "import random\n",
    "import logging\n",
    "import pickle\n",
    "import os \n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import time \n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import dill\n",
    "\n",
    "class Namespace(object):\n",
    "    '''\n",
    "    helps referencing object in a dictionary as dict.key instead of dict['key']\n",
    "    '''\n",
    "    def __init__(self, adict):\n",
    "        self.__dict__.update(adict)\n",
    "\n",
    "\n",
    "\n",
    "with open('../input/data-preprocessing-output/data.pkl', 'rb') as f:\n",
    "    train_data = dill.load(f)\n",
    "    valid_data = dill.load(f)\n",
    "    test_data = dill.load(f)\n",
    "    diffusion_graph = dill.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:05:35.275933Z",
     "iopub.status.busy": "2021-01-31T22:05:35.274500Z",
     "iopub.status.idle": "2021-01-31T22:05:35.276961Z",
     "shell.execute_reply": "2021-01-31T22:05:35.277378Z"
    },
    "papermill": {
     "duration": 0.020951,
     "end_time": "2021-01-31T22:05:35.277504",
     "exception": false,
     "start_time": "2021-01-31T22:05:35.256553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = Namespace({})\n",
    "opt.epoch=50\n",
    "\n",
    "opt.d_model=64\n",
    "opt.n_warmup_steps=1000\n",
    "opt.dropout=0.1\n",
    "opt.log=None\n",
    "#opt.save_path=root_path + \"checkpoint/DiffusionPrediction.pt\"\n",
    "opt.save_mode='best'\n",
    "opt.network=False # use social network; need features or deepwalk embeddings as initial input\n",
    "opt.pos_emb=True\n",
    "opt.warmup=10 # warmup epochs\n",
    "opt.notes=''\n",
    "opt.d_word_vec = opt.d_model\n",
    "opt.user_size = train_data.user_size\n",
    "\n",
    "\n",
    "Constants = Namespace({})\n",
    "Constants.PAD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:05:35.324361Z",
     "iopub.status.busy": "2021-01-31T22:05:35.309449Z",
     "iopub.status.idle": "2021-01-31T22:05:35.326760Z",
     "shell.execute_reply": "2021-01-31T22:05:35.326347Z"
    },
    "papermill": {
     "duration": 0.037243,
     "end_time": "2021-01-31T22:05:35.326884",
     "exception": false,
     "start_time": "2021-01-31T22:05:35.289641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, input_size, d_k=64, d_v=64, n_heads=2, is_layer_norm=True, attn_dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k if d_k is not None else input_size\n",
    "        self.d_v = d_v if d_v is not None else input_size\n",
    "\n",
    "        self.is_layer_norm = is_layer_norm\n",
    "        if is_layer_norm:\n",
    "            self.layer_morm = nn.LayerNorm(normalized_shape=input_size)  # 71\n",
    "\n",
    "        # self.pos_encoding = PositionalEncoding(d_model=input_size, dropout=0.5)\n",
    "        self.W_q = nn.Parameter(torch.Tensor(input_size, n_heads * d_k)) # 72, 8 * 64\n",
    "        self.W_k = nn.Parameter(torch.Tensor(input_size, n_heads * d_k))\n",
    "        self.W_v = nn.Parameter(torch.Tensor(input_size, n_heads * d_v))\n",
    "\n",
    "        self.W_o = nn.Parameter(torch.Tensor(d_v*n_heads, input_size)) # 512 * 72\n",
    "        self.linear1 = nn.Linear(input_size, input_size)\n",
    "        self.linear2 = nn.Linear(input_size, input_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.__init_weights__()\n",
    "        print(self)\n",
    "\n",
    "    def __init_weights__(self):\n",
    "        init.xavier_normal_(self.W_q)\n",
    "        init.xavier_normal_(self.W_k)\n",
    "        init.xavier_normal_(self.W_v)\n",
    "        init.xavier_normal_(self.W_o)\n",
    "\n",
    "        init.xavier_normal_(self.linear1.weight)\n",
    "        init.xavier_normal_(self.linear2.weight)\n",
    "\n",
    "    def FFN(self, X):\n",
    "        output = self.linear2(F.relu(self.linear1(X)))\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask, episilon=1e-6):\n",
    "        '''\n",
    "        :param Q: (*, max_q_words, n_heads, input_size) # 128 * 438 * 64\n",
    "        :param K: (*, max_k_words, n_heads, input_size)\n",
    "        :param V: (*, max_v_words, n_heads, input_size)\n",
    "        :param mask: (*, max_q_words) # 128 * 438\n",
    "        :param episilon:\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        temperature = self.d_k ** 0.5 # d_k = 64 so temp is 8\n",
    "        Q_K = torch.einsum(\"bqd,bkd->bqk\", Q, K) / (temperature + episilon)  # 128 * 438 * 438\n",
    "\n",
    "        if mask is not None:\n",
    "            pad_mask = mask.unsqueeze(dim=-1).expand(-1, -1, K.size(1))  # 128 * 438 * 438\n",
    "            mask = torch.triu(torch.ones(pad_mask.size()), diagonal=1).bool().cuda()\n",
    "            mask_ = mask + pad_mask\n",
    "            Q_K = Q_K.masked_fill(mask_, -2**32+1)\n",
    "\n",
    "        Q_K_score = F.softmax(Q_K, dim=-1)  # (batch_size, max_q_words, max_k_words)\n",
    "        Q_K_score = self.dropout(Q_K_score)\n",
    "\n",
    "        V_att = Q_K_score.bmm(V)  # (*, max_q_words, input_size) # 128 * 438 * 64\n",
    "\n",
    "        return V_att\n",
    "\n",
    "\n",
    "    def multi_head_attention(self, Q, K, V, mask):\n",
    "        '''\n",
    "        :param Q:\n",
    "        :param K:\n",
    "        :param V:\n",
    "        :param mask: (bsz, max_q_words)\n",
    "        :return:\n",
    "        '''\n",
    "        bsz, q_len, _ = Q.size() #[16,438, 72]\n",
    "        bsz, k_len, _ = K.size()\n",
    "        bsz, v_len, _ = V.size()\n",
    "\n",
    "\n",
    "        Q_ = Q.matmul(self.W_q).view(bsz, q_len, self.n_heads, self.d_k) \n",
    "        K_ = K.matmul(self.W_k).view(bsz, k_len, self.n_heads, self.d_k)\n",
    "        V_ = V.matmul(self.W_v).view(bsz, v_len, self.n_heads, self.d_v)\n",
    "\n",
    "        Q_ = Q_.permute(0, 2, 1, 3).contiguous().view(bsz*self.n_heads, q_len, self.d_k)\n",
    "        K_ = K_.permute(0, 2, 1, 3).contiguous().view(bsz*self.n_heads, q_len, self.d_k)\n",
    "        V_ = V_.permute(0, 2, 1, 3).contiguous().view(bsz*self.n_heads, q_len, self.d_v)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(dim=1).expand(-1, self.n_heads, -1)  # For head axis broadcasting.\n",
    "            mask = mask.reshape(-1, mask.size(-1))\n",
    "\n",
    "\n",
    "        V_att = self.scaled_dot_product_attention(Q_, K_, V_, mask)  #128 * 438 * 64\n",
    "        V_att = V_att.view(bsz, self.n_heads, q_len, self.d_v) # 16 * 8 * 438 * 64\n",
    "        V_att = V_att.permute(0, 2, 1, 3).contiguous().view(bsz, q_len, self.n_heads*self.d_v)  # 16 * 438 * 512\n",
    "\n",
    "        output = self.dropout(V_att.matmul(self.W_o)) # (batch_size, max_q_words, input_size)  # #W_o 512 * 72  # 16 * 438 * 72\n",
    "        return output\n",
    "\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        '''\n",
    "        :param Q: (batch_size, max_q_words, input_size) # 16 * 438 * 72 \n",
    "        :param K: (batch_size, max_k_words, input_size)\n",
    "        :param V: (batch_size, max_v_words, input_size)\n",
    "        :return:  output: (batch_size, max_q_words, input_size)  same size as Q\n",
    "        '''\n",
    " \n",
    "        V_att = self.multi_head_attention(Q, K, V, mask)  # mask (16, 243)  #  # 16 * 438 * 72\n",
    "\n",
    "        if self.is_layer_norm:\n",
    "            X = self.layer_morm(Q + V_att)  # (batch_size, max_r_words, embedding_dim) # 16 * 438 * 72\n",
    "\n",
    "            output = self.layer_morm(self.FFN(X) + X)    # 16 * 438 * 72\n",
    "        else:\n",
    "            X = Q + V_att  # 16 * 438 * 72\n",
    "            output = self.FFN(X) + X   # 16 * 438 * 72\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:05:35.361118Z",
     "iopub.status.busy": "2021-01-31T22:05:35.359915Z",
     "iopub.status.idle": "2021-01-31T22:05:35.362789Z",
     "shell.execute_reply": "2021-01-31T22:05:35.362379Z"
    },
    "papermill": {
     "duration": 0.023629,
     "end_time": "2021-01-31T22:05:35.362893",
     "exception": false,
     "start_time": "2021-01-31T22:05:35.339264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_previous_user_mask(seq, user_size):\n",
    "    ''' Mask previous activated users.'''\n",
    "    assert seq.dim() == 2  # 16 * 201\n",
    "    prev_shape = (seq.size(0), seq.size(1), seq.size(1)) # 16, 201, 201\n",
    "    seqs = seq.repeat(1, 1, seq.size(1)).view(seq.size(0), seq.size(1), seq.size(1)) # 16, 201, 201\n",
    "    previous_mask = np.tril(np.ones(prev_shape)).astype('float32')\n",
    "    previous_mask = torch.from_numpy(previous_mask)\n",
    "    if seq.is_cuda:\n",
    "        previous_mask = previous_mask.cuda()\n",
    "\n",
    "    masked_seq = previous_mask * seqs.data.float() # 16, 201, 201\n",
    "\n",
    "\n",
    "    # force the 0th dimension (Constants.PAD) to be masked\n",
    "    PAD_tmp = torch.zeros(seq.size(0), seq.size(1), 1) # 16, 201, 1\n",
    "    if seq.is_cuda:\n",
    "        PAD_tmp = PAD_tmp.cuda()\n",
    "    masked_seq = torch.cat([masked_seq, PAD_tmp], dim=2) # was [16, 201, 201]  becomes [16, 201, 202]\n",
    "    \n",
    "    ans_tmp = torch.zeros(seq.size(0), seq.size(1), user_size) # 16 201 12629\n",
    "    if seq.is_cuda:\n",
    "        ans_tmp = ans_tmp.cuda()\n",
    "        \n",
    "\n",
    "    masked_seq = ans_tmp.scatter_(2, masked_seq.long(), float('-inf'))\n",
    "    masked_seq = Variable(masked_seq, requires_grad=False) # 16 201 12629\n",
    "    return masked_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:05:35.397590Z",
     "iopub.status.busy": "2021-01-31T22:05:35.397068Z",
     "iopub.status.idle": "2021-01-31T22:05:35.400720Z",
     "shell.execute_reply": "2021-01-31T22:05:35.401097Z"
    },
    "papermill": {
     "duration": 0.025975,
     "end_time": "2021-01-31T22:05:35.401222",
     "exception": false,
     "start_time": "2021-01-31T22:05:35.375247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Metrics(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.PAD = 0\n",
    "\n",
    "    def apk(self, actual, predicted, k=10):\n",
    "        \"\"\"\n",
    "        Computes the average precision at k between two lists of items.\n",
    "        actual :  A list of elements that are to be predicted (order doesn't matter)\n",
    "        predicted :  A list of predicted elements (order does matter)\n",
    "        k : int, optional  The maximum number of predicted elements\n",
    "        \"\"\"\n",
    "        score = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(predicted):\n",
    "            if p in actual and p not in predicted[:i]:\n",
    "                num_hits += 1.0\n",
    "                score += num_hits / (i + 1.0)\n",
    "\n",
    "        # if not actual:\n",
    "        # \treturn 0.0\n",
    "        return score / min(len(actual), k)\n",
    "\n",
    "\n",
    "    def compute_metric(self, y_prob, y_true, k_list=[10, 50, 100]):\n",
    "        '''\n",
    "            y_true: (#samples, )\n",
    "            y_pred: (#samples, #users)\n",
    "        '''\n",
    "        scores_len = 0\n",
    "        y_prob = np.array(y_prob)\n",
    "        y_true = np.array(y_true)\n",
    "\n",
    "        scores = {'hits@'+str(k):[] for k in k_list}\n",
    "        scores.update({'map@'+str(k):[] for k in k_list})\n",
    "        for p_, y_ in zip(y_prob, y_true):\n",
    "            if y_ != self.PAD:\n",
    "                scores_len += 1.0\n",
    "                p_sort = p_.argsort()\n",
    "                for k in k_list:\n",
    "                    topk = p_sort[-k:][::-1]\n",
    "                    scores['hits@' + str(k)].extend([1. if y_ in topk else 0.])\n",
    "                    scores['map@'+str(k)].extend([self.apk([y_], topk, k)])\n",
    "\n",
    "        scores = {k: np.mean(v) for k, v in scores.items()}\n",
    "        return scores, scores_len\n",
    "    \n",
    "metric = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:05:35.429909Z",
     "iopub.status.busy": "2021-01-31T22:05:35.429347Z",
     "iopub.status.idle": "2021-01-31T22:05:35.433369Z",
     "shell.execute_reply": "2021-01-31T22:05:35.432931Z"
    },
    "papermill": {
     "duration": 0.01968,
     "end_time": "2021-01-31T22:05:35.433471",
     "exception": false,
     "start_time": "2021-01-31T22:05:35.413791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import GRU\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import TopKPooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:05:35.467322Z",
     "iopub.status.busy": "2021-01-31T22:05:35.465590Z",
     "iopub.status.idle": "2021-01-31T22:05:35.467929Z",
     "shell.execute_reply": "2021-01-31T22:05:35.468329Z"
    },
    "papermill": {
     "duration": 0.022253,
     "end_time": "2021-01-31T22:05:35.468440",
     "exception": false,
     "start_time": "2021-01-31T22:05:35.446187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:05:35.516556Z",
     "iopub.status.busy": "2021-01-31T22:05:35.506833Z",
     "iopub.status.idle": "2021-01-31T22:05:35.519062Z",
     "shell.execute_reply": "2021-01-31T22:05:35.518643Z"
    },
    "papermill": {
     "duration": 0.03786,
     "end_time": "2021-01-31T22:05:35.519165",
     "exception": false,
     "start_time": "2021-01-31T22:05:35.481305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DyHGCN_H(nn.Module):\n",
    "\n",
    "    def __init__(self, diffusion_graph, opt):\n",
    "        super(DyHGCN_H, self).__init__()\n",
    "        ntoken = opt.user_size # training 12629\n",
    "        self.ninp = 64\n",
    "        self.user_size = ntoken # training 12629\n",
    "        self.pos_dim = 8\n",
    "        self.__name__ = \"DyHGCN_H\"\n",
    "        \n",
    "        #\n",
    "        self.num_of_nodes = ntoken\n",
    "        self.in_channels = 64\n",
    "        #\n",
    "        self.embedding = nn.Embedding(ntoken, self.ninp, padding_idx=0) # 12629, 64\n",
    "        self.ratio = self.ninp / self.num_of_nodes\n",
    "        self.pooling_layer = TopKPooling( self.ninp, self.ratio)\n",
    "        \n",
    "        self.gnn1 = GCNConv(self.ninp, self.ninp,  bias = False)\n",
    "\n",
    "        self.recurrent_layer1 = GRU(input_size = self.ninp,\n",
    "                                   hidden_size = self.ninp,\n",
    "                                   num_layers = 1)\n",
    "        \n",
    "        self.gnn2 = GCNConv(self.ninp, self.ninp, bias = False)\n",
    "        self.recurrent_layer2 = GRU(input_size = self.ninp,\n",
    "                           hidden_size = self.ninp,\n",
    "                           num_layers = 1)\n",
    "        self.diffusion_graph_list = diffusion_graph\n",
    "        #------------------\n",
    "        self.pos_embedding = nn.Embedding(1000, self.pos_dim)\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(8, 0.1)\n",
    "\n",
    "        self.decoder_attention = TransformerBlock(input_size=self.ninp + self.pos_dim, n_heads=8)  #72\n",
    "        self.linear = nn.Linear(self.ninp + self.pos_dim, ntoken) # 72 * 12629\n",
    "\n",
    "\n",
    "    def forward(self, input, input_timestamp):\n",
    "        mask = (input == Constants.PAD)\n",
    "\n",
    "        batch_size, max_len = input.size()  # 16, 201\n",
    "        \n",
    "        batch_t = torch.arange(max_len).expand((batch_size, max_len)).cuda()\n",
    "\n",
    "        order_embed = self.pos_embedding(batch_t)   # 16, 201, 8\n",
    "        order_embed = self.pos_encoder(order_embed) # 16, 201, 8\n",
    "\n",
    "        batch_all = torch.arange(self.user_size).cuda()\n",
    "\n",
    "        dyemb = torch.zeros(batch_size, max_len, self.ninp).cuda() # 16, 201, 64\n",
    "\n",
    "        dynamic_node_emb_dict = dict()\n",
    "        graph_embedding_list = list() \n",
    "        X_tilde_all = []\n",
    "        for key in sorted(self.diffusion_graph_list.keys()):\n",
    "            graph = self.diffusion_graph_list[key] \n",
    "            graph_edge_index = graph.edge_index.cuda()\n",
    "            embeds = self.embedding(batch_all.cuda())\n",
    "            \n",
    "            graph_x_embeddings = embeds.cuda()  # 16, 12500, 64  # [12629, 64]\n",
    "            X_tilde = self.pooling_layer(graph_x_embeddings, graph_edge_index) # [64, 64]\n",
    "            X_tilde_all.append(X_tilde[0][None,:,:])\n",
    "\n",
    "            graph_x_embeddings = nn.Dropout(0.3)(self.gnn1(graph_x_embeddings, graph_edge_index))  # [12629, 64]\n",
    "            graph_x_embeddings = nn.Dropout(0.1)(self.gnn2(graph_x_embeddings, graph_edge_index))  # [12629, 64]\n",
    "\n",
    "\n",
    "\n",
    "            graph_embedding_list.append(graph_x_embeddings)\n",
    "            dynamic_node_emb_dict[key] = graph_x_embeddings\n",
    "        \n",
    "        W1 = self.gnn1.weight[None, :, :] # [1, 64, 64]\n",
    "        #W2 = self.gnn2.weight[None, :, :] # [1, 64, 64]\n",
    "\n",
    "        X_tilde_all = torch.cat(X_tilde_all, dim = 0) # [8, 64, 64]\n",
    "\n",
    "        _, W1 = self.recurrent_layer1(X_tilde_all, W1) #[1, 64, 64] , [1, 64, 64] \n",
    "        #X_tilde_all, W2 = self.recurrent_layer1(X_tilde_all, W2) #[1, 64, 64] , [1, 64, 64] \n",
    "\n",
    "        self.gnn1.weight = torch.nn.Parameter(W1.squeeze())\n",
    "        #self.gnn2.weight = torch.nn.Parameter(W2.squeeze())\n",
    "\n",
    "\n",
    "        latest_timestamp = sorted(dynamic_node_emb_dict.keys())[-1]\n",
    "        \n",
    "        step_len = 5 \n",
    "\n",
    "        for t in range(0, max_len, step_len):\n",
    "            try:\n",
    "                la_timestamp = torch.max(input_timestamp[:, t:t+step_len]).item()\n",
    "\n",
    "                if la_timestamp < 1:\n",
    "                    break \n",
    "                latest_timestamp = la_timestamp \n",
    "            except Exception:\n",
    "                # print (input_timestamp[:, t:t+step_len])\n",
    "                pass \n",
    "\n",
    "            his_timestamp = sorted(dynamic_node_emb_dict.keys())[-1]\n",
    "            for x in sorted(dynamic_node_emb_dict.keys()):\n",
    "                if x <= latest_timestamp:\n",
    "                    his_timestamp = x\n",
    "                    continue\n",
    "                else:\n",
    "                    break \n",
    "            \n",
    "\n",
    "            graph_dynamic_embeddings = dynamic_node_emb_dict[his_timestamp]\n",
    "            \n",
    "            dyemb[:, t:t+step_len, :] = F.embedding(input[:, t:t+step_len].cuda(), graph_dynamic_embeddings.cuda())\n",
    "\n",
    "\n",
    "        final_embed = torch.cat([dyemb, order_embed], dim=-1).cuda() # dynamic_node_emb\n",
    "        \n",
    "        \n",
    "        att_out = self.decoder_attention(final_embed.cuda(), final_embed.cuda(), final_embed.cuda(), mask=mask.cuda())   # 16 * 438 * 72\n",
    "        att_out = att_out.cuda()\n",
    "\n",
    "        output = self.linear(att_out.cuda())  # (bsz, user_len, |U|) linear( 72 , 12629)  # 16 * 438 * 12629\n",
    "        \n",
    "        mask = get_previous_user_mask(input.cuda(), self.user_size)   #user_size 12629\n",
    "        output = output.cuda() + mask.cuda()  # 16 * 438 * 12629\n",
    "        return output.view(-1, output.size(-1)) #16 * 438 , 12629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:05:35.555155Z",
     "iopub.status.busy": "2021-01-31T22:05:35.553119Z",
     "iopub.status.idle": "2021-01-31T22:06:09.441751Z",
     "shell.execute_reply": "2021-01-31T22:06:09.440811Z"
    },
    "papermill": {
     "duration": 33.910067,
     "end_time": "2021-01-31T22:06:09.441905",
     "exception": false,
     "start_time": "2021-01-31T22:05:35.531838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerBlock(\n",
      "  (layer_morm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
      "  (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "  (linear2): Linear(in_features=72, out_features=72, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = DyHGCN_H(diffusion_graph, opt)  \n",
    "loss_func = nn.CrossEntropyLoss(size_average=False, ignore_index=Constants.PAD)\n",
    "\n",
    "params = model.parameters()\n",
    "optimizerAdam = torch.optim.Adam(params, betas=(0.9, 0.98), eps=1e-09)\n",
    "\n",
    "class ScheduledOptim(object): # A wrapper class for optimizer  for learning rate scheduling\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "\n",
    "    def step(self):  # \"Step by the inner optimizer\"\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grad(self): # \"Zero out the gradients by the inner optimizer\"\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def update_learning_rate(self):   #''' Learning rate scheduling per step '''\n",
    "        self.n_current_steps += 1\n",
    "        new_lr = np.power(self.d_model, -0.5) * np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = new_lr\n",
    "            \n",
    "            \n",
    "optimizer = ScheduledOptim(optimizerAdam, opt.d_model, opt.n_warmup_steps)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "    \n",
    "\n",
    "validation_history = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:06:09.479883Z",
     "iopub.status.busy": "2021-01-31T22:06:09.477108Z",
     "iopub.status.idle": "2021-01-31T22:06:09.482395Z",
     "shell.execute_reply": "2021-01-31T22:06:09.481957Z"
    },
    "papermill": {
     "duration": 0.026612,
     "end_time": "2021-01-31T22:06:09.482502",
     "exception": false,
     "start_time": "2021-01-31T22:06:09.455890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def doit(data_partition, label):\n",
    "    ''' Epoch operation in evaluation phase '''\n",
    "    model.eval()\n",
    "\n",
    "    k_list=[10, 50, 100]\n",
    "    scores_checker = {}\n",
    "    for k in k_list:\n",
    "        scores_checker['hits@' + str(k)] = 0\n",
    "        scores_checker['map@' + str(k)] = 0\n",
    "\n",
    "    n_total_words_checker = .01\n",
    "    \n",
    "    for i, batch in enumerate(data_partition): \n",
    "            print(\"{} batch \".format(label), i)\n",
    "            # prepare data\n",
    "            tgt, tgt_timestamp = batch  # tgt = 16, 209\n",
    "\n",
    "            y_gold = tgt[:, 1:].contiguous().view(-1).detach().cpu().numpy() # 16*208\n",
    "            input_tgt = tgt[:, :-1]\n",
    "            input_timestamp = tgt_timestamp[:, :-1] \n",
    "            # forward\n",
    "            pred = model(input_tgt, input_timestamp)\n",
    "            y_pred = pred.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "            scores_batch, scores_len = metric.compute_metric(y_pred, y_gold, k_list)\n",
    "            n_total_words_checker += scores_len\n",
    "            for k in k_list:\n",
    "                scores_checker['hits@' + str(k)] += scores_batch['hits@' + str(k)] * scores_len\n",
    "                scores_checker['map@' + str(k)] += scores_batch['map@' + str(k)] * scores_len\n",
    "            break;\n",
    "\n",
    "    for k in k_list:\n",
    "        scores_checker['hits@' + str(k)] = scores_checker['hits@' + str(k)] / n_total_words_checker\n",
    "        scores_checker['map@' + str(k)] = scores_checker['map@' + str(k)] / n_total_words_checker\n",
    "\n",
    "    for metric_ in scores_checker.keys():\n",
    "        print(metric_ + ' ' + str(scores_checker[metric_]))\n",
    "\n",
    "    #test_scores = test_epoch(model, test_data, diffusion_graph)\n",
    "    #for metric_ in test_scores.keys():\n",
    "    #                print(metric_ + ' ' + str(test_scores[metric_]))\n",
    "    model.train()\n",
    "    return scores_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.013401,
     "end_time": "2021-01-31T22:06:09.509548",
     "exception": false,
     "start_time": "2021-01-31T22:06:09.496147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:06:09.551988Z",
     "iopub.status.busy": "2021-01-31T22:06:09.551264Z",
     "iopub.status.idle": "2021-01-31T22:07:14.053429Z",
     "shell.execute_reply": "2021-01-31T22:07:14.054174Z"
    },
    "papermill": {
     "duration": 64.53116,
     "end_time": "2021-01-31T22:07:14.054343",
     "exception": false,
     "start_time": "2021-01-31T22:06:09.523183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch  0  loss:  9513.2470703125  acc: 0.0 n_correct: 0.0 n_words:  996.0\n",
      "Training batch  10  loss:  4264.0576171875  acc: 0.0 n_correct: 0.0 n_words:  445.0\n",
      "Training batch  20  loss:  4893.3984375  acc: 0.0 n_correct: 0.0 n_words:  511.0\n",
      "Training batch  30  loss:  5566.83935546875  acc: 0.0 n_correct: 0.0 n_words:  582.0\n",
      "Training batch  40  loss:  4065.058349609375  acc: 0.0005681818181818182 n_correct: 1.0 n_words:  430.0\n",
      "Training batch  50  loss:  3646.0859375  acc: 0.002577319587628866 n_correct: 4.0 n_words:  384.0\n",
      "Training batch  60  loss:  3889.54296875  acc: 0.0043859649122807015 n_correct: 8.0 n_words:  410.0\n",
      "Training batch  70  loss:  4148.44140625  acc: 0.0037162162162162164 n_correct: 11.0 n_words:  442.0\n",
      "Training batch  80  loss:  4634.73388671875  acc: 0.004310344827586207 n_correct: 16.0 n_words:  498.0\n",
      "Training batch  90  loss:  3076.833984375  acc: 0.005780346820809248 n_correct: 16.0 n_words:  336.0\n",
      "Training batch  100  loss:  8491.0849609375  acc: 0.0055248618784530384 n_correct: 16.0 n_words:  925.0\n",
      "Training batch  110  loss:  4349.8037109375  acc: 0.009345794392523364 n_correct: 16.0 n_words:  483.0\n",
      "Training batch  120  loss:  4589.845703125  acc: 0.0036101083032490976 n_correct: 16.0 n_words:  505.0\n",
      "Training batch  130  loss:  7831.62060546875  acc: 0.0028653295128939827 n_correct: 16.0 n_words:  855.0\n",
      "Training batch  140  loss:  1063.4801025390625  acc: 0.043478260869565216 n_correct: 16.0 n_words:  123.0\n",
      "Training batch  150  loss:  3920.992919921875  acc: 0.005813953488372093 n_correct: 16.0 n_words:  454.0\n",
      "Training batch  160  loss:  5959.912109375  acc: 0.004784688995215311 n_correct: 16.0 n_words:  679.0\n",
      "Training batch  170  loss:  3460.935546875  acc: 0.012658227848101266 n_correct: 16.0 n_words:  394.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scores_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c47239a996ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mscores_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mscores_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"valid_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mscores_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_train' is not defined"
     ]
    }
   ],
   "source": [
    "start_again = False\n",
    "if start_again:\n",
    "    scores_train = []\n",
    "    scores_valid = []\n",
    "    scores_test = []\n",
    "\n",
    "model.train()\n",
    "for _ in range(100):\n",
    "    total_loss = 0.0\n",
    "    n_total_words = 0.0\n",
    "    n_total_correct = 0.0\n",
    "    batch_num = 0.0\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        i = i \n",
    "        batch = batch\n",
    "        # prepare data\n",
    "        tgt, tgt_timestamp = (item.cuda() for item in batch)\n",
    "\n",
    "        gold = tgt[:, 1:]\n",
    "        input_tgt = tgt[:, :-1]\n",
    "        input_timestamp = tgt_timestamp[:, :-1] \n",
    "\n",
    "\n",
    "        n_words = gold.data.ne(Constants.PAD).sum().float()\n",
    "        n_total_words += n_words\n",
    "        batch_num += tgt.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(input_tgt, input_timestamp)  ##16 * 438 , 12629\n",
    "        # backward\n",
    "\n",
    "        loss = loss_func(pred, gold.contiguous().view(-1))   ##gold is 16 * 438 \n",
    "        pred = pred.max(1)[1]\n",
    "\n",
    "        gold = gold.contiguous().view(-1)\n",
    "        n_correct = pred.data.eq(gold.data)\n",
    "        n_correct = n_correct.masked_select(gold.ne(Constants.PAD).data).sum().float()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.update_learning_rate()\n",
    "\n",
    "        # note keeping\n",
    "        n_total_correct += n_correct\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Training batch \", i, \" loss: \", loss.item(), \" acc:\", (n_correct.item()/len(pred)), \"n_correct:\",n_correct.item(),\n",
    "                 \"n_words: \", n_words.item())\n",
    "   \n",
    "\n",
    "    train_loss =  total_loss/n_total_words \n",
    "    train_accu =  n_total_correct/n_total_words\n",
    "    \n",
    "\n",
    "    scores_train.append(doit(train_data,\"train_data\"))\n",
    "    scores_valid.append(doit(valid_data,\"valid_data\"))\n",
    "    scores_test.append(doit(test_data,\"test_data\"))\n",
    "    print('  - (Training)   loss: {loss: 8.5f}, accuracy: {accu:3.3f} %'.format(loss=train_loss, accu=100 * train_accu))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:07:14.097554Z",
     "iopub.status.busy": "2021-01-31T22:07:14.096736Z",
     "iopub.status.idle": "2021-01-31T22:07:14.681504Z",
     "shell.execute_reply": "2021-01-31T22:07:14.680877Z"
    },
    "papermill": {
     "duration": 0.608445,
     "end_time": "2021-01-31T22:07:14.681680",
     "exception": false,
     "start_time": "2021-01-31T22:07:14.073235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data batch  0\n",
      "hits@10 0.058331713007972005\n",
      "map@10 0.047290353045748725\n",
      "hits@50 0.0944418210605261\n",
      "map@50 0.04885299331294\n",
      "hits@100 0.13610733035193465\n",
      "map@100 0.04940690460038843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hits@10': 0.058331713007972005,\n",
       " 'map@10': 0.047290353045748725,\n",
       " 'hits@50': 0.0944418210605261,\n",
       " 'map@50': 0.04885299331294,\n",
       " 'hits@100': 0.13610733035193465,\n",
       " 'map@100': 0.04940690460038843}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doit(test_data,\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:07:14.730453Z",
     "iopub.status.busy": "2021-01-31T22:07:14.725353Z",
     "iopub.status.idle": "2021-01-31T22:07:14.754899Z",
     "shell.execute_reply": "2021-01-31T22:07:14.755540Z"
    },
    "papermill": {
     "duration": 0.053903,
     "end_time": "2021-01-31T22:07:14.755743",
     "exception": false,
     "start_time": "2021-01-31T22:07:14.701840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d5ebe484f8e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscores_valid2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_train' is not defined"
     ]
    }
   ],
   "source": [
    "scores_train2 = pd.DataFrame(scores_train)\n",
    "scores_valid2 = pd.DataFrame(scores_valid)\n",
    "scores_test2 = pd.DataFrame(scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:07:14.840081Z",
     "iopub.status.busy": "2021-01-31T22:07:14.839161Z",
     "iopub.status.idle": "2021-01-31T22:07:14.874397Z",
     "shell.execute_reply": "2021-01-31T22:07:14.873670Z"
    },
    "papermill": {
     "duration": 0.086995,
     "end_time": "2021-01-31T22:07:14.874568",
     "exception": false,
     "start_time": "2021-01-31T22:07:14.787573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e78fbda0f626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_test2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_test2' is not defined"
     ]
    }
   ],
   "source": [
    "scores_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T22:07:14.964353Z",
     "iopub.status.busy": "2021-01-31T22:07:14.963473Z",
     "iopub.status.idle": "2021-01-31T22:07:14.996082Z",
     "shell.execute_reply": "2021-01-31T22:07:14.997438Z"
    },
    "papermill": {
     "duration": 0.083205,
     "end_time": "2021-01-31T22:07:14.997703",
     "exception": false,
     "start_time": "2021-01-31T22:07:14.914498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_train2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c28862d564f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmetr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores_train2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores_train2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores_valid2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores_test2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_train2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for metr in scores_train2.columns:\n",
    "    x_train = scores_train2[metr]\n",
    "    x_valid = scores_valid2[metr]\n",
    "    x_test = scores_test2[metr]\n",
    "    plt.plot(x_train)\n",
    "    plt.plot(x_valid)\n",
    "    plt.plot(x_test)\n",
    "    \n",
    "    plt.title(metr)\n",
    "\n",
    "    plt.legend(('Training set','Validation set','Test set'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.037988,
     "end_time": "2021-01-31T22:07:15.076575",
     "exception": false,
     "start_time": "2021-01-31T22:07:15.038587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.036575,
     "end_time": "2021-01-31T22:07:15.150310",
     "exception": false,
     "start_time": "2021-01-31T22:07:15.113735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 177.750983,
   "end_time": "2021-01-31T22:07:17.940223",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-31T22:04:20.189240",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
